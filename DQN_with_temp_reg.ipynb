{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN-with-temp-reg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yaQF1_iBYekN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RL-Adventure code: https://github.com/higgsfield/RL-Adventure/blob/master/1.dqn.ipynb\n",
        "# PyTorch\n",
        "# Understood code : to certain extent, with almost no doubts, but go through again\n",
        "# DQN uses CNN: Atari one does, simple change for OpenAI gym\n",
        "# GPU support : Yes\n",
        "# Double Q learning support: Yes\n",
        "# PER: Has prioritized experience replay\n",
        "# Comparison with DeepMind paper results: For pong, the score of 19 was achieved\n",
        "# Remarks: Does not use 2 separate networks (i.e. target network and policy network)\n",
        "# Pong DQN running time (for 1,400,000 frames with PongNoFrameskip-v4) : around 6.5 hrs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j3Sxh3e2XFa0",
        "colab_type": "code",
        "outputId": "cc509c39-e153-4436-d0fc-4e97111cba90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/higgsfield/RL-Adventure"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'RL-Adventure'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Total 55 (delta 0), reused 0 (delta 0), pack-reused 55\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PhwgiUZbLmHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd \n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moA4B3n2LmHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8pH0d6HLmHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Use Cuda</h3>"
      ]
    },
    {
      "metadata": {
        "id": "CHFK5oGBLmHk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VE_XN11mLmHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Replay Buffer</h2>"
      ]
    },
    {
      "metadata": {
        "id": "JiyXGY8ULmHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "#Added space for single number from p in buffer functions #>> temp reg edit \n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "    \n",
        "    def push(self, state, action, reward, next_state, done, p_val):\n",
        "        state      = np.expand_dims(state, 0)\n",
        "        next_state = np.expand_dims(next_state, 0)\n",
        "        self.buffer.append((state, action, reward, next_state, done, p_val))\n",
        "    \n",
        "    def sample(self, batch_size):\n",
        "        state, action, reward, next_state, done, p_val = zip(*random.sample(self.buffer, batch_size))\n",
        "        return np.concatenate(state), action, reward, np.concatenate(next_state), done, p_val\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SXauzlqLmIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Deep Q Network</h2>"
      ]
    },
    {
      "metadata": {
        "id": "PVoo1LAGLmI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(env.observation_space.shape[0], 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, env.action_space.n)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "    \n",
        "    def act(self, state, epsilon):\n",
        "        if random.random() > epsilon:\n",
        "            state   = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
        "            q_value = self.forward(state)\n",
        "            action = int(q_value.max(1)[1].data[0].cpu().int().numpy())\n",
        "        else:\n",
        "            action = random.randrange(env.action_space.n)\n",
        "        return action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3msl8-hLmJG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Computing Temporal Difference Loss</h2>"
      ]
    },
    {
      "metadata": {
        "id": "i6S5wviiLmJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_td_loss(batch_size, beta):\n",
        "    state, action, reward, next_state, done, p_val = replay_buffer.sample(batch_size)\n",
        "\n",
        "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
        "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
        "    action     = Variable(torch.LongTensor(action))\n",
        "    reward     = Variable(torch.FloatTensor(reward))\n",
        "    done       = Variable(torch.FloatTensor(done))\n",
        "    # Using value from p vector >> temp reg edit\n",
        "    p_val      = Variable(torch.FloatTensor(p_val))\n",
        "\n",
        "    q_values      = model(state)\n",
        "    next_q_values = model(next_state)\n",
        "\n",
        "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "    next_q_value     = next_q_values.max(1)[0]\n",
        "    \n",
        "    # Changing the target to the temporally regularized target >> temp reg edit \n",
        "    expected_q_value = reward + gamma * ((1-beta)* next_q_value * (1 - done) + beta * p_val)\n",
        "    loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
        "        \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Or8fnrRLLmJQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot(frame_idx, rewards, losses):\n",
        "    clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(131)\n",
        "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
        "    plt.plot(rewards)\n",
        "    plt.subplot(132)\n",
        "    plt.title('loss')\n",
        "    plt.plot(losses)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R0FpydBJLmJa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Training</h2>"
      ]
    },
    {
      "metadata": {
        "id": "MDHf92n3LmJc",
        "colab_type": "code",
        "outputId": "90138cfa-6969-429a-87e5-993b1d2d35e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "for beta in [0,0.1,0.2,0.3,0.7]: #temp reg edit\n",
        "    for lamb in [0.1,0.2,0.3]:   #temp reg edit\n",
        "        if beta == 0 and lamb>0.1:\n",
        "            continue\n",
        "        for i in range(1,6):\n",
        "            env_id = \"MountainCar-v0\"\n",
        "            env = gym.make(env_id)\n",
        "\n",
        "            #setting the seeds  \n",
        "            import random\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            random.seed(i)\n",
        "            np.random.seed(i)\n",
        "            env.seed(i)\n",
        "            torch.manual_seed(i)\n",
        "            torch.cuda.manual_seed_all(i)\n",
        "\n",
        "            epsilon_start = 1.0\n",
        "            epsilon_final = 0.01\n",
        "            epsilon_decay = 500\n",
        "\n",
        "            epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n",
        "\n",
        "            plt.plot([epsilon_by_frame(i) for i in range(10000)])\n",
        "\n",
        "            model = DQN(env.observation_space.shape[0], env.action_space.n)\n",
        "\n",
        "            if USE_CUDA:\n",
        "                model = model.cuda()\n",
        "\n",
        "            optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "            replay_buffer = ReplayBuffer(1000)\n",
        "\n",
        "            num_frames = 250000\n",
        "            batch_size = 32\n",
        "            gamma      = 0.99\n",
        "\n",
        "            losses = []\n",
        "            all_rewards = []\n",
        "            episode_reward = 0\n",
        "            action_change_frequencies = []           #>> plotting edit\n",
        "            num_action_changes = 0                   #>> plotting edit\n",
        "            episodic_return_deque = deque(np.zeros(20),maxlen=20) #>> plotting edit\n",
        "            mean_episodic_return = []  #>> plotting edit\n",
        "            prev_action = 0 #>> plotting edit\n",
        "\n",
        "            state = env.reset()\n",
        "            #initialize p vector as q(state,a) for all a #>> temp reg edit\n",
        "            state_var = Variable(torch.FloatTensor(np.float32(state)))\n",
        "            p = model(state_var).detach().cpu().numpy()\n",
        "\n",
        "            for frame_idx in range(1, num_frames + 1):\n",
        "                epsilon = epsilon_by_frame(frame_idx)\n",
        "                action = model.act(state, epsilon)\n",
        "\n",
        "                if frame_idx>1 and done!=True and action!=prev_action:  #>> plotting edit\n",
        "                    num_action_changes+=1  #>> plotting edit\n",
        "\n",
        "                prev_action = action #>> plotting edit\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                #push the \"action\" component of p into the buffer also #>> temp reg edit \n",
        "                replay_buffer.push(state, action, reward, next_state, done, p[action])\n",
        "\n",
        "                state = next_state\n",
        "                episode_reward += reward\n",
        "\n",
        "                if done:\n",
        "                    state = env.reset()\n",
        "                    all_rewards.append(episode_reward)\n",
        "                    episodic_return_deque.append(episode_reward) #>> plotting edit\n",
        "                    episode_reward = 0\n",
        "                    #initialize p vector as q(state,a) for all a #>> temp reg edit\n",
        "                    state_var = Variable(torch.FloatTensor(np.float32(state)))\n",
        "                    p = model(state_var).detach().cpu().numpy()\n",
        "\n",
        "                if len(replay_buffer) > batch_size:\n",
        "                    #Need to pass beta into this >> temp reg edit \n",
        "                    loss = compute_td_loss(batch_size, beta = beta)\n",
        "                    losses.append(loss.data.item())\n",
        "\n",
        "                if frame_idx % 200 == 0:\n",
        "                    plot(frame_idx, all_rewards, losses)\n",
        "\n",
        "                if frame_idx % 2000 ==0: #>> plotting edit\n",
        "                    mean_episodic_return.append([frame_idx,np.mean(episodic_return_deque)]) #>> plotting edit\n",
        "                    action_change_frequencies.append([frame_idx,num_action_changes])         #>> plotting edit\n",
        "                    num_action_changes = 0    #>> plotting edit\n",
        "\n",
        "                #update the p vector for q(state,a) for all a #>> temp reg edit\n",
        "                state_var = Variable(torch.FloatTensor(np.float32(state)))\n",
        "                new_q = model(state_var).detach().cpu().numpy()\n",
        "                p = (1-lamb)*new_q + lamb*p\n",
        "\n",
        "            np.savetxt(env_id+',beta='+str(beta)+',lambda='+str(lamb)+',rewards_run='+str(i)+'.csv',all_rewards)  #>> plotting edit\n",
        "            np.savetxt(env_id+',beta='+str(beta)+',lambda='+str(lamb)+',losses_run='+str(i)+'.csv',losses) #>> plotting edit\n",
        "            np.savetxt(env_id+',beta='+str(beta)+',lambda='+str(lamb)+',mean_rewards_run='+str(i)+'.csv',mean_episodic_return)  #>> plotting edit\n",
        "            np.savetxt(env_id+',beta='+str(beta)+',lambda='+str(lamb)+',action_changes_run='+str(i)+'.csv',action_change_frequencies) #>> plotting edit\n",
        "            torch.save(model.state_dict(),env_id+',beta='+str(beta)+',lambda='+str(lamb)+',weights_run='+str(i)+'.pt')  #>> plotting edit"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zw_z46lcLmJp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p><hr></p>"
      ]
    },
    {
      "metadata": {
        "id": "H4A_YSrPLmJs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Atari Environment</h1>"
      ]
    },
    {
      "metadata": {
        "id": "bVDbJUNhf1wq",
        "colab_type": "code",
        "outputId": "08dcfd92-a01b-4cc0-fb7b-943e888d522f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd RL-Adventure/\n",
        "!rm common/__init__.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/RL-Adventure\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pzSGWQlF1Uer",
        "colab_type": "code",
        "outputId": "1a1e75f4-bdd3-48df-c74e-f726fd451284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Enabling frame skip to be a parameter\n",
        "%%writefile common/wrappers.py\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import gym\n",
        "from gym import spaces\n",
        "import cv2\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "class NoopResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env, noop_max=30):\n",
        "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
        "        No-op is assumed to be action 0.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.noop_max = noop_max\n",
        "        self.override_num_noops = None\n",
        "        self.noop_action = 0\n",
        "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
        "        self.env.reset(**kwargs)\n",
        "        if self.override_num_noops is not None:\n",
        "            noops = self.override_num_noops\n",
        "        else:\n",
        "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
        "        assert noops > 0\n",
        "        obs = None\n",
        "        for _ in range(noops):\n",
        "            obs, _, done, _ = self.env.step(self.noop_action)\n",
        "            if done:\n",
        "                obs = self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)\n",
        "\n",
        "class EpisodicLifeEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
        "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.lives = 0\n",
        "        self.was_real_done  = True\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "        self.was_real_done = done\n",
        "        # check current lives, make loss of life terminal,\n",
        "        # then update lives to handle bonus lives\n",
        "        lives = self.env.unwrapped.ale.lives()\n",
        "        if lives < self.lives and lives > 0:\n",
        "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
        "            # so its important to keep lives > 0, so that we only reset once\n",
        "            # the environment advertises done.\n",
        "            done = True\n",
        "        self.lives = lives\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\"Reset only when lives are exhausted.\n",
        "        This way all states are still reachable even though lives are episodic,\n",
        "        and the learner need not know about any of this behind-the-scenes.\n",
        "        \"\"\"\n",
        "        if self.was_real_done:\n",
        "            obs = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            # no-op step to advance from terminal/lost life state\n",
        "            obs, _, _, _ = self.env.step(0)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        return obs\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
        "        self._skip       = skip\n",
        "\n",
        "    def reset(self):\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
        "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        # Note that the observation on the done=True frame\n",
        "        # doesn't matter\n",
        "        max_frame = self._obs_buffer.max(axis=0)\n",
        "\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "class ClipRewardEnv(gym.RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.RewardWrapper.__init__(self, env)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
        "        return np.sign(reward)\n",
        "\n",
        "class WarpFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "        self.width = 84\n",
        "        self.height = 84\n",
        "        self.observation_space = spaces.Box(low=0, high=255,\n",
        "            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, frame):\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
        "        return frame[:, :, None]\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env, k):\n",
        "        \"\"\"Stack k last frames.\n",
        "        Returns lazy array, which is much more memory efficient.\n",
        "        See Also\n",
        "        --------\n",
        "        baselines.common.atari_wrappers.LazyFrames\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.k = k\n",
        "        self.frames = deque([], maxlen=k)\n",
        "        shp = env.observation_space.shape\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=np.uint8)\n",
        "\n",
        "    def reset(self):\n",
        "        ob = self.env.reset()\n",
        "        for _ in range(self.k):\n",
        "            self.frames.append(ob)\n",
        "        return self._get_ob()\n",
        "\n",
        "    def step(self, action):\n",
        "        ob, reward, done, info = self.env.step(action)\n",
        "        self.frames.append(ob)\n",
        "        return self._get_ob(), reward, done, info\n",
        "\n",
        "    def _get_ob(self):\n",
        "        assert len(self.frames) == self.k\n",
        "        return LazyFrames(list(self.frames))\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        # careful! This undoes the memory optimization, use\n",
        "        # with smaller replay buffers only.\n",
        "        return np.array(observation).astype(np.float32) / 255.0\n",
        "\n",
        "class LazyFrames(object):\n",
        "    def __init__(self, frames):\n",
        "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
        "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
        "        buffers.\n",
        "        This object should only be converted to numpy array before being passed to the model.\n",
        "        You'd not believe how complex the previous solution was.\"\"\"\n",
        "        self._frames = frames\n",
        "        self._out = None\n",
        "\n",
        "    def _force(self):\n",
        "        if self._out is None:\n",
        "            self._out = np.concatenate(self._frames, axis=2)\n",
        "            self._frames = None\n",
        "        return self._out\n",
        "\n",
        "    def __array__(self, dtype=None):\n",
        "        out = self._force()\n",
        "        if dtype is not None:\n",
        "            out = out.astype(dtype)\n",
        "        return out\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._force())\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self._force()[i]\n",
        "\n",
        "def make_atari(env_id,frame_skip=4):\n",
        "    env = gym.make(env_id)\n",
        "    assert 'NoFrameskip' in env.spec.id\n",
        "    env = NoopResetEnv(env, noop_max=30)\n",
        "    env = MaxAndSkipEnv(env, skip=frame_skip)\n",
        "    return env\n",
        "\n",
        "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n",
        "    \"\"\"Configure environment for DeepMind-style Atari.\n",
        "    \"\"\"\n",
        "    if episode_life:\n",
        "        env = EpisodicLifeEnv(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = WarpFrame(env)\n",
        "    if scale:\n",
        "        env = ScaledFloatFrame(env)\n",
        "    if clip_rewards:\n",
        "        env = ClipRewardEnv(env)\n",
        "    if frame_stack:\n",
        "        env = FrameStack(env, 4)\n",
        "    return env\n",
        "\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Image shape to num_channels x weight x height\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.swapaxes(observation, 2, 0)\n",
        "    \n",
        "\n",
        "def wrap_pytorch(env):\n",
        "    return ImageToPyTorch(env)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting common/wrappers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V780OUkLLmJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ehSqx7nLmJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env_id = \"FreewayNoFrameskip-v4\"                    # Need to use NoFrameskip-v4 versions of Atari games in Gym, else frames will be skipped too much\n",
        "env    = make_atari(env_id, frame_skip=4)        # Added frameskip parameter \n",
        "env    = wrap_deepmind(env)                      # Need to pass frame_stack=True as an argument here. 4 frames are stacked as state\n",
        "env    = wrap_pytorch(env)\n",
        "\n",
        "#setting the seeds  \n",
        "i=1\n",
        "import random\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(i)\n",
        "np.random.seed(i)\n",
        "env.seed(i)\n",
        "torch.manual_seed(i)\n",
        "torch.cuda.manual_seed_all(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdt0RzYrLmKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CnnDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(CnnDQN, self).__init__()\n",
        "        \n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size(), 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_actions)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    \n",
        "    def feature_size(self):\n",
        "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
        "    \n",
        "    def act(self, state, epsilon):\n",
        "        if random.random() > epsilon:\n",
        "            state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
        "            q_value = self.forward(state)\n",
        "            action = int(q_value.max(1)[1].data[0].cpu().int().numpy())\n",
        "        else:\n",
        "            action = random.randrange(env.action_space.n)\n",
        "        return action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ciuHjGKLmKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
        "\n",
        "if USE_CUDA:\n",
        "    model = model.cuda()\n",
        "    \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "replay_initial = 10000\n",
        "replay_buffer = ReplayBuffer(100000)     # Deepmind paper used replay buffer of size 1,000,000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxgRXzDDLmKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epsilon_start = 1.0\n",
        "epsilon_final = 0.01     # Deepmind paper used epsilon annealed linearly from 1 to 0.1 over first 1 million frames and fixed at 0.1 thereafter\n",
        "epsilon_decay = 30000\n",
        "\n",
        "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9yJOWA5LmKj",
        "colab_type": "code",
        "outputId": "f471d749-57d4-4a9a-b43d-aa0c9a2e6cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot([epsilon_by_frame(i) for i in range(1000000)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f11991480f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXkQk5RT0IiIpp6AXEUk5Bb2ISMr9P71I2vU1yVUaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pLBo_nL3LmKz",
        "colab_type": "code",
        "outputId": "8ace31d4-195b-4d55-f1f8-eda2ac4e1b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "num_frames = 2000000   # Deepmind paper used 10 million frames\n",
        "batch_size = 32        # Same as Deepmind\n",
        "gamma      = 0.99    \n",
        "beta = 0.0 #>> temp reg edit\n",
        "lamb = 0.2 #>> temp reg edit\n",
        "\n",
        "losses = []\n",
        "all_rewards = []\n",
        "episode_reward = 0\n",
        "\n",
        "state = env.reset()\n",
        "#initialize p vector as q(state,a) for all a #>> temp reg edit\n",
        "state_var = Variable(torch.FloatTensor(np.float32(state)))\n",
        "state_var = torch.unsqueeze(state_var,0)\n",
        "p = (model(state_var)[0]).detach().cpu().numpy()\n",
        "\n",
        "for frame_idx in range(1, num_frames + 1):\n",
        "    epsilon = epsilon_by_frame(frame_idx)\n",
        "    action = model.act(state, epsilon)\n",
        "    \n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    #push the \"action\" component of p into the buffer also #>> temp reg edit \n",
        "    replay_buffer.push(state, action, reward, next_state, done, p[action])\n",
        "    \n",
        "    state = next_state\n",
        "    episode_reward += reward\n",
        "    \n",
        "    if done:\n",
        "        state = env.reset()\n",
        "        all_rewards.append(episode_reward)\n",
        "        episode_reward = 0\n",
        "        #initialize p vector as q(state,a) for all a #>> temp reg edit\n",
        "        state_var = Variable(torch.FloatTensor(np.float32(state)))\n",
        "        state_var = torch.unsqueeze(state_var,0)\n",
        "        p = (model(state_var)[0]).detach().cpu().numpy()\n",
        "        \n",
        "    if len(replay_buffer) > replay_initial:\n",
        "        #Need to pass beta into this >> temp reg edit \n",
        "        loss = compute_td_loss(batch_size, beta = beta)\n",
        "        losses.append(loss.data.item())\n",
        "        \n",
        "    if frame_idx % 10000 == 0:\n",
        "        plot(frame_idx, all_rewards, losses)\n",
        "    \n",
        "    #update the p vector for q(state,a) for all a #>> temp reg edit\n",
        "    state_var = Variable(torch.FloatTensor(np.float32(state)))\n",
        "    state_var = torch.unsqueeze(state_var,0)\n",
        "    new_q = (model(state_var)[0]).detach().cpu().numpy()\n",
        "    p = (1-lamb)*new_q + lamb*p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvwAAAE/CAYAAAA6zBcIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI7jOI7j5BhP+B3HcRzHcRwnx/wDNrL28QpIHjAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HcEuWmKxm_WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "i=1\n",
        "\n",
        "with open('rewards_run='+str(i)+'.csv','w') as f:\n",
        "    writer = csv.writer(f);\n",
        "    writer.writerows(zip(all_rewards));\n",
        "\n",
        "with open('losses_run='+str(i)+'.csv','w') as f:\n",
        "    writer = csv.writer(f);\n",
        "    writer.writerows(zip(losses));\n",
        "\n",
        "torch.save(model.state_dict(),'weights_run='+str(i)+'.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rqlux-nL7wza",
        "colab_type": "code",
        "outputId": "397a1203-1f78-440c-c901-7846cf255ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "d = deque(np.zeros(9))\n",
        "d.append(1)\n",
        "print(np.mean(d))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oyowvt_Z8ZbN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}